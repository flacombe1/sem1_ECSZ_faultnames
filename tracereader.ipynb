{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9WMB_PWlxZtf"
   },
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import geopy\n",
    "import pygmt\n",
    "import pyproj\n",
    "from geopy.distance import geodesic\n",
    "from geopy.distance import distance\n",
    "from os import system as sys\n",
    "\n",
    "path = \"C:/Users/19049/coding_files/data/CFM5.3_traces.ts\"\n",
    "subset = \"C:/Users/19049/coding_files/data/subset.ts\"\n",
    "folder = \"C:/Users/19049/coding_files/faults/\"\n",
    "wb_2b = \"C:/Users/19049/coding_files/wb_2b/\"\n",
    "\n",
    "to_open = path\n",
    "\n",
    "#currently the path is saevd as a .ts file, it'd be nice to have a conversion automatically from utm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vY9atfWm9hc7"
   },
   "outputs": [],
   "source": [
    "#I did not write this https://stackoverflow.com/questions/185936/how-to-delete-the-contents-of-a-folder\n",
    "#Just a tool to clear the faults folder- but could be useful later when reading in new data\n",
    "# def Delete_faults_content():\n",
    "#     [f.unlink() for f in Path(\"C:/Users/19049/coding_files/faults\").glob(\"*\") if f.is_file()]\n",
    "# Delete_faults_content()\n",
    "# def Delete_wb_2b_content():\n",
    "#     [f.unlink() for f in Path(\"C:/Users/19049/coding_files/wb_2b\").glob(\"*\") if f.is_file()]\n",
    "# Delete_wb_2b_content()\n",
    "\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "        \n",
    "for filename in os.listdir(wb_2b):\n",
    "    file_path = os.path.join(wb_2b, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in os.listdir(folder):\n",
    "#     os.system(folder + 'rm *')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vF1dDxdX_CYk"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "#what i've got:\n",
    "#strip the crap from the fault name line (the tag and excess quotes, can expand to more stuff)\n",
    "#open a fault folder to stick the coords in\n",
    "\n",
    "#What i want:\n",
    "#how tf do I put the coords into the new files now- I think I can use the current name and use the make_new_fault as a ticker, so the \"put number in folder\" function is dumb and every time it sees\n",
    "#a coord it will just add it to the fault that is currently \"name\" and that should change since the for loop goes down the list in order\n",
    "#it'd be nice to get a counter as a discrepancy check\n",
    "\n",
    "#strips \"> \" and extra \"\" from line and sets it to global name\n",
    "#change the calling of line to a thing within the function itself instead of depending on 'line' having the same name in the for loop\n",
    "def redefine_name():\n",
    "\n",
    "    t1_name = line\n",
    "    t2_name = re.sub(\"[> ]\", \"\", t1_name)\n",
    "    name = ast.literal_eval(t2_name)\n",
    "\n",
    "#makes an empty pandas dataframe using the empty list l\n",
    "def make_new_fault():\n",
    "    global l1\n",
    "    l1 = pd.DataFrame(l,columns = ['Easting(m)','Northing(m)','Elevation(m)'])\n",
    "\n",
    "#the line being read is delimited and turned from a line of strings into a line of floats\n",
    "#then it is apended to the l1 dataframe\n",
    "def number_line():\n",
    "    string_line = line.split()\n",
    "    float_list = list(map(float, string_line))\n",
    "    l1.loc[len(l1)] = float_list\n",
    "\n",
    "#takes the finished l1 dataframe and names it the current fault trace, making it a csv    \n",
    "def save_line():\n",
    "    l1.to_csv(folder+thing+\".csv\")\n",
    "    \n",
    "#what we want to do is move the current fault in names, to a folder by providing the current path and the path to the folder, also renames!\n",
    "def move():\n",
    "    shutil.move(folder+fault, wb_2b+short+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Easting(m)  Northing(m)  Elevation(m)\n",
      "0   407001.1563   3906157.50         760.0\n",
      "1   406313.9375   3907289.00         750.0\n",
      "2   406092.1875   3908817.75         792.0\n",
      "3   405931.8750   3910852.75         905.0\n",
      "4   405538.5313   3912022.50        1010.0\n",
      "..          ...          ...           ...\n",
      "69  408141.0000   4024031.50        1131.0\n",
      "70  407937.2187   4025852.50        1142.0\n",
      "71  407708.6562   4027649.50        1157.0\n",
      "72  407413.0000   4029714.75        1141.0\n",
      "73  402188.7500   4040125.25        1644.0\n",
      "\n",
      "[74 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#13 faults that are included in the project that we want to make worlbuilder files of\n",
    "# format: '*_fault',\\n\n",
    "faults_to_include = [\n",
    "    'Panamint_Valley_fault',\n",
    "    'Southern_Death_Valley_fault',\n",
    "    'Black_Mountain_fault',\n",
    "    'Owl_Lake_fault',\n",
    "    'Hunter_Mountain_fault',\n",
    "    'Ash_Hill_fault',\n",
    "    'Independence_Sierra_Nevada_fault', #Gotta add the _fault identification bit cause of\n",
    "    'Independence_fault',               #these two lines\n",
    "    'Little_Lake_fault',\n",
    "    'Airport_Lake_fault',\n",
    "    'Eastern_Little_Lake_north_north_east_cross_fault',\n",
    "    'Owens_Valley_fault',\n",
    "    'Northern_Death_Valley_fault'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, as the reader is looking through each line, instead of writing out the whole thing we want it to aknowledge that the line has the want in it\n",
    "we can do that by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzVFOJOaRoAS",
    "outputId": "fe2d5c10-1add-4f0c-bfc8-8abcc44a8c40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black_Mountain_fault\n",
      "Northern_Death_Valley_fault\n",
      "Southern_Death_Valley_fault\n",
      "Owl_Lake_fault\n",
      "Ash_Hill_fault\n",
      "Airport_Lake_fault\n",
      "Hunter_Mountain_fault\n",
      "Little_Lake_fault\n",
      "Eastern_Little_Lake_north_north_east_cross_fault\n",
      "Owens_Valley_fault\n",
      "Panamint_Valley_fault\n",
      "Independence_fault\n",
      "Independence_Sierra_Nevada_fault\n"
     ]
    }
   ],
   "source": [
    "#l being here resets the dataframe every time it's run, though I can probably just define make_new_fault pd.dataframe([],columns....) instead of making l=[]\n",
    "\n",
    "l = []\n",
    "with open(to_open, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"> \"):\n",
    "            is_number = False\n",
    "            flag = []\n",
    "            for short in faults_to_include:\n",
    "                if short in line:\n",
    "                    thing = short\n",
    "                    flag.append('yes')\n",
    "                    make_new_fault()\n",
    "                    print(thing)\n",
    "                else:\n",
    "                    flag.append('no')\n",
    "        elif line.startswith(\"#\"):\n",
    "            pass\n",
    "        else:\n",
    "            is_number = True\n",
    "            while is_number == True:\n",
    "                if 'yes' in flag:\n",
    "                    number_line()\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "                break\n",
    "        save_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moves the files in the faults folder with the short names defined in want to the worldbuilder to be folder (wb_2b)\n",
    "#now when I say move, it deletes the file in the fault folder, so it's not there anymore and has to be remade\n",
    "fault_names = os.listdir(r\"C:\\Users\\19049\\coding_files\\faults\")\n",
    "for fault in fault_names:\n",
    "    for short in faults_to_include:\n",
    "        if short in fault:\n",
    "            move()\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I\"m thinking that now we can identify the faults we want out of the pile, we put them into another folder, which we can then run indescriminate code on, which I suppose the purpose of that code\n",
    "#would be to convert the trace data to a worldbuilder file format? which I think daniel has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##northing is adjusted by subtracting 3870000, easting by subtracting 345000\n",
    "for file in os.listdir(wb_2b):\n",
    "    if file.endswith('.csv'):\n",
    "        read = wb_2b+file\n",
    "        df = pd.read_csv(read,\n",
    "                header = 0,\n",
    "                usecols=['Easting(m)', 'Northing(m)', 'Elevation(m)']\n",
    "                )\n",
    "        ar = df.to_numpy[:1, 0] - 345000\n",
    "        thing = df['Easting(m)']-345000\n",
    "        for each in df['Easting(m)'][1:]:\n",
    "            new = each - 345000\n",
    "            # print(new)\n",
    "            \n",
    "        # print(file)\n",
    "        # print(thing)\n",
    "        # print(file)\n",
    "        # print(df.loc[:, ('Easting(m)', 'Northing(m)')], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so what this does is take the files that are csv files in wb_2b and returns the cartesian coordinate\n",
    "#ready for conversion into worldbuilder files\n",
    "#northing is adjusted by subtracting 3870000, easting by subtracting 345000\n",
    "#What I want this damn thing to do is take the two values e and n, change em, then throw them into a new file\n",
    "def get_coords(folder_2b):\n",
    "    for file in os.listdir(folder_2b):\n",
    "        if file.endswith('.csv'):\n",
    "            print(file)\n",
    "            open_up = folder_2b+file\n",
    "            with open(open_up) as csvfile:\n",
    "                spamreader = csv.reader(csvfile)\n",
    "                spamdictreader = csv.DictReader(csvfile)\n",
    "                #spamwriter = csv.writer(csvfile, fieldnames=['Easting(m)', 'Northing(m)'])\n",
    "                for line in spamdictreader:\n",
    "                    \n",
    "                    #print(map(float, line['Easting(m)'])+', '+map(float, line['Northing(m)']))\n",
    "                    print(line)\n",
    "get_coords(wb_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace(x, y):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So basically what I want to do is take the trace data that we have and ignore the elevation, since we can do stuff with that later (like elevation based temperature changes). So for now jut get the trace\n",
    "#data into the worldbuilder files with 90 degree dip\n",
    "#below is Daniel stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_string(length, thickness, angle, top_truncation, coordinate, total_sections, segment_num, current_segment):\n",
    "\n",
    "    '''\n",
    "    Writes the string that defines segments of a slab to the world builder file\n",
    "\n",
    "    When initializing a slab in Worldbuilder, you must specify the same number of segments for each section along strike\n",
    "    of the slab, which is troublesome since some sections of slab are much longer than others. To get around this,\n",
    "    the slab is initialized with the same number of segments as the section with the maximum number of segments. \n",
    "    Then, sections with less than this number of segments are assigned filler sections with lengths of 0 m until\n",
    "    they reach the required number of segments\n",
    "\n",
    "    length          = the length of a given segment\n",
    "    thickness       = the thickness of a given segment\n",
    "    angle           = the dip of a given segment\n",
    "    coordinate      = the trench coordinate index coupled to the current section\n",
    "    total_sections  = the number of sections making up the slab\n",
    "    segment_num     = the number of segments making up each section\n",
    "    current_segment = the current segment index of a section\n",
    "    '''\n",
    " \n",
    "    string_total = ''\n",
    "    filler_segment_number = abs(len(thickness) - segment_num)\n",
    "    if current_segment < filler_segment_number:\n",
    "        if len(thickness[0]) > 1:\n",
    "            # Here we proceed as above, adding the segment strings until we reach the end of the array\n",
    "            string_total += '{\"length\":' + str(0.0) + ', \"thickness\":' + str([np.max(thickness), np.max(thickness)]) + ', \"angle\":' + str([0.0, 0.0]) + '},\\n'# \\\n",
    "                           # ', \"angle\":' + str([0,0]) + '},\\n'\n",
    "            return string_total\n",
    "        \n",
    "        else:\n",
    "            # Here we proceed as above, adding the segment strings until we reach the end of the array\n",
    "            string_total += '{\"length\":' + str(0.0) + ', \"thickness\":' + str([np.max(thickness)]) + ', \"angle\":' + str([0.0, 0.0]) + '},\\n'# \\\n",
    "                           # ', \"angle\":' + str([0,0]) + '},\\n'\n",
    "            return string_total\n",
    "        \n",
    "        # Now we have reached the end of the array, but need to fill out the amount of segments to reach the maximum\n",
    "        # segment number. Add segments with lengths of 1m, thicknesses of 1m, and dips of 1 degree until this is the case.\n",
    "    else:\n",
    "        if current_segment != segment_num - 1:\n",
    "            string_total = '{\"length\":' + str(length[current_segment - filler_segment_number]) + ', \"thickness\":' + str(thickness[current_segment - filler_segment_number]) + \\\n",
    "                            ', \"angle\":' + str(angle[current_segment - filler_segment_number]) + ', \"top truncation\":' + str(top_truncation) + '},\\n'\n",
    "            return string_total\n",
    "\n",
    "        elif current_segment == (segment_num - 1) and coordinate == total_sections:\n",
    "            string_total += '{\"length\":' + str(length[current_segment - filler_segment_number]) + ', \"thickness\":' + str(thickness[current_segment - filler_segment_number]) + \\\n",
    "                        ', \"angle\":' + str(angle[current_segment - filler_segment_number]) + ', \"top truncation\":' + str(top_truncation) + '}]}\\n'\n",
    "            return string_total\n",
    "\n",
    "        else:\n",
    "            string_total += '{\"length\":' + str(length[current_segment - filler_segment_number]) + ', \"thickness\":' + str(thickness[current_segment - filler_segment_number]) + \\\n",
    "                        ', \"angle\":' + str(angle[current_segment - filler_segment_number]) + ', \"top truncation\":' + str(top_truncation) + '}]},\\n'\n",
    "            return string_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_section(world_builder_file, profile_directory, xshift, yshift, slab_thickness, top_truncation, coordinate_system):\n",
    "    \n",
    "    '''\n",
    "    Calculates dip, thickness, and length of segments then uses segment_string() to create the string for the world builder file.\n",
    "    This function has the option to vary the slab thickness between certain depths. If the varialbe slab_thickness is a scalar,\n",
    "    a constant thickness is assumed for the entire section. To vary thickness, slab_thickness must be an array where each entry is an \n",
    "    array with length two. The entries of this array are the thickness of the slab and the depth to where \n",
    "    that thickness occurs. For example, to have the slab be 100km thick between 0 <= depth <= 200km, and then\n",
    "    have the thickness increase to 150km for depth > 200km, the variable slab_thickness would need to be set as:\n",
    "\n",
    "    slab_thickness = [ [100e3, 200e3], [150e3, 1e10] ]\n",
    "\n",
    "    Where 1e10 was chosen to be a depth so high it would never be reached. Slab thickness and dip are varied gradually \n",
    "    down dip\n",
    "\n",
    "    world_builder_file = the name of the world builder file\n",
    "    profile_directory  = directory containing the world builder file\n",
    "    xshift             = the amount of shift in the x direction, m\n",
    "    yshift             = the amount of shift in the y direction, m\n",
    "    slab_thickness     = the thickness of the slab, scaler for uniform thickness, array for variable, km\n",
    "    '''\n",
    "  \n",
    "    # Import packages for spherical coordinate systems\n",
    "    import geopy\n",
    "    from geopy.distance import geodesic\n",
    "    from geopy.distance import distance\n",
    "    import pyproj\n",
    "    geodesic = pyproj.Geod(ellps='WGS84')\n",
    "    \n",
    "    # Create an array which stores the length of each profile, the longest profile determines the number of\n",
    "    # segments required for initializing the slab\n",
    "    length = []\n",
    "    for file in np.sort(os.listdir(profile_directory)):\n",
    "        length.append(len(np.loadtxt(fname=profile_directory + file)))\n",
    "    segment_num = max(length)\n",
    "    total_sections = len(os.listdir(profile_directory)) - 1\n",
    "    \n",
    "    # This loop initializes the slab with the correct number of segments\n",
    "    world_builder_file.write('\"segments\":[\\n')\n",
    "    for i in range(segment_num):\n",
    "        if i != segment_num - 1:\n",
    "            world_builder_file.write('{\"length\":0, \"thickness\":[0.0], \"angle\":[0]},\\n')\n",
    "        else:\n",
    "            world_builder_file.write('{\"length\":0, \"thickness\":[0.0], \"angle\":[0]}],\\n\\n')\n",
    "\n",
    "    # This loops through all sections and determines the thickness, dip, and length of each segment\n",
    "    world_builder_file.write('    \"sections\":[')\n",
    "    index = 0\n",
    "    for file in np.sort(os.listdir(profile_directory)):\n",
    "        index += 1\n",
    "        filename = os.path.join(profile_directory, file)\n",
    "\n",
    "        track_x = np.loadtxt(fname=filename, usecols=0) + xshift\n",
    "        track_y = np.loadtxt(fname=filename, usecols=1) + yshift\n",
    "        track_z = np.loadtxt(fname=filename, usecols=2)\n",
    "\n",
    "        slab_length = 0\n",
    "        segment_length = []\n",
    "        dip_holder = [0]\n",
    "        \n",
    "        # Here we check to see if the thickness is set to vary along the slab by checking if slab_thickness is\n",
    "        # a scalar or not. Dip is also computed and stored for output to the world builder file here\n",
    "        if hasattr(slab_thickness, \"__len__\"):\n",
    "            thick_holder = [slab_thickness[index - 1][:, 0][0]]\n",
    "            for i in range(1, len(track_z)):\n",
    "                thick_index = np.min(np.where( slab_thickness[index - 1][:, 1] > np.abs(track_z[i]) ))\n",
    "                thick_holder.append(slab_thickness[index - 1][:, 0][thick_index])\n",
    "                \n",
    "                if coordinate_system == 'Cartesian':\n",
    "                    slab_cart_proj = np.sqrt( (track_x[i] - track_x[i - 1])**2 + (track_y[i] - track_y[i - 1])**2 )\n",
    "                    slab_length = np.sqrt( (track_x[i] - track_x[i - 1])**2 + (track_y[i] - track_y[i - 1])**2 + (track_z[i] - track_z[i - 1])**2)\n",
    "                    riserun = (track_z[i - 1] - track_z[i]) / (slab_cart_proj)\n",
    "                    \n",
    "                elif coordinate_system == 'Spherical':\n",
    "                    fwd_az, back_az, slab_cart_proj_m = geodesic.inv(track_x[i-1], track_y[i-1], track_x[i], track_y[i])\n",
    "                    slab_cart_proj = slab_cart_proj_m / 1e3\n",
    "                    slab_length = np.sqrt( slab_cart_proj**2 + (track_z[i] - track_z[i - 1])**2)\n",
    "                    riserun = (track_z[i - 1] - track_z[i]) / (slab_cart_proj)\n",
    "                    \n",
    "                segment_length.append(slab_length * 1000)\n",
    "                dip_holder.append(np.rad2deg(np.arctan(abs(riserun))))\n",
    "                \n",
    "            segment_thickness = []\n",
    "            for k in range(len(thick_holder) - 1):\n",
    "                if k != int(len(thick_holder) - 1):\n",
    "                    segment_thickness.append([thick_holder[k], thick_holder[k + 1]])\n",
    "                else:\n",
    "                    segment_thickness.append([thick_holder[k]])\n",
    "         \n",
    "        else:\n",
    "            segment_thickness = []\n",
    "            for i in range(1, len(track_z)):\n",
    "                segment_thickness.append([slab_thickness])\n",
    "                \n",
    "                if coordinate_system == 'Cartesian':\n",
    "                    slab_cart_proj = np.sqrt( (track_x[i] - track_x[i - 1])**2 + (track_y[i] - track_y[i - 1])**2 )\n",
    "                    slab_length = np.sqrt( (track_x[i] - track_x[i - 1])**2 + (track_y[i] - track_y[i - 1])**2 + (track_z[i] - track_z[i - 1])**2)\n",
    "                    \n",
    "                elif coordinate_system == 'Spherical':\n",
    "                    fwd_az, back_az, slab_cart_proj_m = geodesic.inv(track_x[i-1], track_y[i-1], track_x[i], track_y[i])\n",
    "                    slab_cart_proj = slab_cart_proj_m / 1e3\n",
    "                    slab_length = np.sqrt( slab_cart_proj**2 + (track_z[i] - track_z[i - 1])**2)\n",
    "                    \n",
    "                riserun = (track_z[i - 1] - track_z[i]) / (slab_cart_proj)\n",
    "                segment_length.append(slab_length * 1000)\n",
    "                dip_holder.append(np.rad2deg(np.arctan(abs(riserun))))\n",
    "                \n",
    "        dips = []\n",
    "        for k in range(len(dip_holder) - 1):\n",
    "            if k != int(len(dip_holder) - 1):\n",
    "                dips.append([dip_holder[k], dip_holder[k + 1]])\n",
    "            else:\n",
    "                dips.append([dip_holder[k]])\n",
    "        \n",
    "        # Write to the World Builder File\n",
    "        world_builder_file.write('    {\"coordinate\":' + str(index - 1) + ',\\n')\n",
    "        world_builder_file.write('     \"segments\":[')\n",
    "        for current_segment in range(segment_num):\n",
    "            world_builder_file.write('    ' + segment_string(segment_length, segment_thickness, dips, top_truncation, index - 1, total_sections, segment_num, current_segment))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
