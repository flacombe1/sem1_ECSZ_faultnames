{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9WMB_PWlxZtf"
   },
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import geopy\n",
    "import pygmt\n",
    "import pyproj\n",
    "from geopy.distance import geodesic\n",
    "from geopy.distance import distance\n",
    "from os import system as sys\n",
    "\n",
    "path = \"C:/Users/19049/coding_files/data/CFM5.3_traces.ts\"\n",
    "subset = \"C:/Users/19049/coding_files/data/subset.ts\"\n",
    "folder = \"C:/Users/19049/coding_files/faults/\"\n",
    "sub_folder = \"C:/Users/19049/coding_files/faults/wb\"\n",
    "wb_2b = \"C:/Users/19049/coding_files/wb_2b/\"\n",
    "\n",
    "to_open = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are iterating through each line or row of the CFM5.3traces.ts file\n",
    "#there is a \"> \" at the beginning of each line within the data file that I'm using to identify that the current line is a fault name\n",
    "#flags the type of line currently being evaluated\n",
    "#List that tracks the 'yes' and 'no' answers of whether the fault name is one included in faults_to_include- lets us ignore the fault data we don't want but it needs to be reset after each fault real_name check\n",
    "#(These lines check each provided name in faults_to_include to the fault name being evaluated\n",
    "#progress tracker, since this takes a second on my machine\n",
    "#We want to make a new df for each fault\n",
    "#we only need one 'yes' to indicate that this is a fault we want\n",
    "#there will be a number of 'no' in each fault tracker list equal to the number of faults_to_include elements for those we don't want, and -1 for those we do\n",
    "#There are 15 #s at the beginning of the file that we want to explicitly avoid\n",
    "#flags the type of line currently being evaluated\n",
    "#The while loop is needed because with the is_number flag we can go through an ambiguous number of lines underneath each fault name until we reach a new line beginning with \"> \" where we will reset everything an begin a new df\n",
    "#if there is one 'yes' answer within the tracker list then it will adjust to df: purpose of this is to only take data from a fault we want and ignore the rest\n",
    "#adjusting to df translates the single string line to a list of floats and adjusts the easting and northing values by -345000 and -3870000 respectively\n",
    "#Saves the current line of adjusted values to a csv under the current real_name of the fault. make sure is in line with while, that gets messed up a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#13 faults that are included in the project that we want to make worlbuilder files of\n",
    "# format: '*_fault',\\n\n",
    "faults_to_include = [\n",
    "    '-Panamint_Valley_fault',\n",
    "    '-Southern_Death_Valley_fault',\n",
    "    '-Black_Mountain_fault',\n",
    "    '-Owl_Lake_fault',\n",
    "    '-Hunter_Mountain_fault',\n",
    "    '-Ash_Hill_fault',\n",
    "    '-Independence_Sierra_Nevada_fault', #Gotta add the _fault identification bit cause of\n",
    "    '-Independence_fault',               #these two lines\n",
    "    '-Little_Lake_fault',\n",
    "    '-Airport_Lake_fault',\n",
    "    '-Eastern_Little_Lake_north_north_east_cross_fault',\n",
    "    '-Owens_Valley_fault',\n",
    "    '-Northern_Death_Valley_fault',\n",
    "    '-Casmalia_fault', #cause of this guy we gotta have the '-' at the beginning, not sure if this will bug the wb file, but i think it can be stripped later\n",
    "    'thing'                             #if thing shows up in files, stuff is wack\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vF1dDxdX_CYk"
   },
   "outputs": [],
   "source": [
    "#makes an empty pandas dataframe to fill the adjusted values with\n",
    "#\",'Elevation(m)'\"\n",
    "def make_empty_fault_df():\n",
    "    global fault_dataframe\n",
    "    fault_dataframe = pd.DataFrame([],columns = ['Easting(m)','Northing(m)'])\n",
    "\n",
    "#the line being read is delimited and turned from a line of strings into a line of floats\n",
    "#then it is apended to the fault_dataframe dataframe with the elements adjusted\n",
    "#add \", float_list[2]\" to end of fault_dataframe to log the elevation\n",
    "#fault_dataframe.loc[len(fault_dataframe)]\n",
    "def adjust_to_df():\n",
    "        string_line = line.split()\n",
    "        float_list = list(map(float, string_line))\n",
    "        fault_dataframe.loc[len(fault_dataframe)] = float_list[0]-345000, float_list[1]-3870000\n",
    "        # print(bruh)\n",
    "        \n",
    "def adjust_to_wb():\n",
    "        \n",
    "        string_line = line.split()\n",
    "        float_list = list(map(float, string_line))\n",
    "        coors = [float_list[0]-345000, float_list[1]-3870000]\n",
    "        coordinates.append(coors)  \n",
    "        return coordinates\n",
    "    \n",
    "        \n",
    "\n",
    "#takes the finished fault_dataframe df and names it the current fault trace, making it a csv    \n",
    "def save_to_file():\n",
    "    fault_dataframe.to_csv(folder+use_name+\".csv\")\n",
    "def save_to_wb():\n",
    "    wb.append(feature_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzVFOJOaRoAS",
    "outputId": "fe2d5c10-1add-4f0c-bfc8-8abcc44a8c40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black_Mountain_fault\n",
      "Northern_Death_Valley_fault\n",
      "Southern_Death_Valley_fault\n",
      "Casmalia_fault\n",
      "Casmalia_fault\n",
      "Owl_Lake_fault\n",
      "Ash_Hill_fault\n",
      "Airport_Lake_fault\n",
      "Hunter_Mountain_fault\n",
      "Little_Lake_fault\n",
      "Eastern_Little_Lake_north_north_east_cross_fault\n",
      "Owens_Valley_fault\n",
      "Panamint_Valley_fault\n",
      "Independence_fault\n",
      "Independence_Sierra_Nevada_fault\n"
     ]
    }
   ],
   "source": [
    "#makes files containing each fault data, doesn't need to be run but helps with debugging\n",
    "with open(to_open, encoding='utf-8') as f:\n",
    "    for line in f:                                          \n",
    "        if line.startswith(\"> \"):                           \n",
    "            is_number = False                               \n",
    "            included_fault_tracker = [] \n",
    "            \n",
    "            for real_name in faults_to_include:                            \n",
    "                if real_name in line:                       \n",
    "                    print(real_name)\n",
    "                    global use_name\n",
    "                    use_name = real_name                                        \n",
    "                    make_empty_fault_df()                   \n",
    "                    included_fault_tracker.append('yes')     \n",
    "                else:                                       \n",
    "                    included_fault_tracker.append('no')     \n",
    "        elif line.startswith(\"#\"):                          \n",
    "            pass                                            \n",
    "        else:                                               \n",
    "            is_number = True                                \n",
    "            while is_number == True:                        \n",
    "                if 'yes' in included_fault_tracker:         \n",
    "                    adjust_to_df()                      \n",
    "                    \n",
    "                else:                           \n",
    "                    pass\n",
    "                break\n",
    "            save_to_file()                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(\"C:/Users/19049/coding_files/*\"):\n",
    "    if \"wb_wip.txt\" in file:\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Black_Mountain_fault\n",
      "-Northern_Death_Valley_fault\n",
      "-Southern_Death_Valley_fault\n",
      "-Casmalia_fault\n",
      "-Owl_Lake_fault\n",
      "-Ash_Hill_fault\n",
      "-Airport_Lake_fault\n",
      "-Hunter_Mountain_fault\n",
      "-Little_Lake_fault\n",
      "-Eastern_Little_Lake_north_north_east_cross_fault\n",
      "-Owens_Valley_fault\n",
      "-Panamint_Valley_fault\n",
      "-Independence_fault\n",
      "-Independence_Sierra_Nevada_fault\n"
     ]
    }
   ],
   "source": [
    "#Takes the raw data file and writes it to a wb file in one step\n",
    "\n",
    "#clears working file so we don't stack\n",
    "for file in glob.glob(\"C:/Users/19049/coding_files/*\"):\n",
    "    if \"wb_wip.txt\" in file:\n",
    "        os.remove(file)\n",
    "        \n",
    "#initial condidtions and intitiations of flags\n",
    "wb=[]\n",
    "model = '\"model\":\"fault\"'\n",
    "version = '\"version\":\"0.5\"'\n",
    "dip_point = '\"dip point\":[0,0]'\n",
    "Associated_with_current_fault = True\n",
    "coordinates = []\n",
    "included_fault_tracker = []\n",
    "global name\n",
    "\n",
    "#determine last line\n",
    "with open(to_open) as f:\n",
    "    for line in f:\n",
    "        pass\n",
    "    global last_line\n",
    "    last_line = line\n",
    "\n",
    "#initialize the wb file\n",
    "with open(\"wb_wip.txt\", \"a\") as f:\n",
    "    f.write('{')\n",
    "    f.write('\\n')\n",
    "    f.write('\\t')\n",
    "    f.write(version)\n",
    "    f.write(', \\n')\n",
    "    f.write('\\t')\n",
    "    f.write('\"features\":')\n",
    "    f.write('\\n')\n",
    "    f.write('\\t')\n",
    "    f.write('[')\n",
    "    f.write('\\n')\n",
    "    \n",
    "with open(to_open) as f:\n",
    "    for line in f:\n",
    "        #purpose of this is that the last set of coordinates were not being outputted, since the output was dependent on a new fault being read in, so the above for loop finds the last line and this if statement outputs the stuff if it is the last line. Might be a stupid way of doing this but idk how else to do it. Isn't invoked in the full data read, but still needed for robustness.\n",
    "        if line == last_line:\n",
    "            #flags to let the script know the flow of what it's supposed to do- wrapping the coordinates associated with each fault name\n",
    "            #this one is here to differentiate between being done with the current set of coordinates for a given fault or not, setting it to false means we're done with that set of coordinates and can send the wrapped set to the wb file\n",
    "            #by wrapped I mean the coordinates for a fault are all together within a list and can be associated with the name and whatever else of the fault\n",
    "            Associated_with_current_fault = False\n",
    "            is_number = False\n",
    "            while Associated_with_current_fault == False:\n",
    "                #sorts faults that we want from ones we don't based on the fault tracker flag\n",
    "                if 'yes' in included_fault_tracker:\n",
    "                    with open(\"wb_wip.txt\", \"a\") as f:\n",
    "                        codename = '\"name\":'+name                        \n",
    "                        f.write('\\t')\n",
    "                        f.write('{')\n",
    "                        f.write(model)\n",
    "                        f.write(',')\n",
    "                        f.write(codename)\n",
    "                        f.write(',')\n",
    "                        f.write(dip_point)\n",
    "                        f.write(', \\n')\n",
    "                        f.write('\\t')\n",
    "                        f.write('\\t')\n",
    "                        f.write('\"coordinates\":[')\n",
    "                        f.write('\\n')\n",
    "                        f.write(', \\n'.join(str(i) for i in coordinates))\n",
    "                        f.write('\\n')\n",
    "                        f.write('],')\n",
    "                        f.write('\\n')\n",
    "                        f.write('\\t')\n",
    "                        f.write('\\t')\n",
    "                        f.write('\"segments\" n stuff go here')\n",
    "                        f.write('\\n')\n",
    "                        f.write('\\t')\n",
    "                        f.write('\\t')\n",
    "                        f.write('}') #this one should be the last one and doesn't have a ,\n",
    "                        f.write('\\n')\n",
    "                        \n",
    "                    #print(coordinates)\n",
    "                break\n",
    "        #the beginning of each new fault will have this as the starting characters of that line and every coordinate until the start of the next fault will be associated with it, \n",
    "        if line.startswith(\"> \"):\n",
    "            #flags to let the script know the flow of what it's supposed to do- wrapping the coordinates associated with each fault name\n",
    "            Associated_with_current_fault = False\n",
    "            is_number = False\n",
    "            while Associated_with_current_fault == False:\n",
    "                #sorts faults that we want from ones we don't based on the fault tracker flag\n",
    "                if 'yes' in included_fault_tracker:\n",
    "                    with open(\"wb_wip.txt\", \"a\") as f:\n",
    "                        codename = '\"name\":'+name                        \n",
    "                        f.write('\\t')\n",
    "                        f.write('{')\n",
    "                        f.write(model)\n",
    "                        f.write(',')\n",
    "                        f.write(codename)\n",
    "                        f.write(',')\n",
    "                        f.write(dip_point)\n",
    "                        f.write(', \\n')\n",
    "                        f.write('\\t')\n",
    "                        f.write('\\t')\n",
    "                        f.write('\"coordinates\":[')\n",
    "                        f.write('\\n')\n",
    "                        f.write(', \\n'.join(str(i) for i in coordinates))\n",
    "                        f.write('\\n')                        \n",
    "                        f.write('],')\n",
    "                        f.write('\\n')\n",
    "                        f.write('\\t')\n",
    "                        f.write('\\t')\n",
    "                        f.write('\"segments\" n stuff go here')\n",
    "                        f.write('\\n')\n",
    "                        f.write('\\t')\n",
    "                        f.write('\\t')\n",
    "                        f.write('},') #has ,\n",
    "                        f.write('\\n')\n",
    "                       \n",
    "                    #print(coordinates)\n",
    "                break\n",
    "            #initiates the fault tracker list and resets it\n",
    "            included_fault_tracker = []\n",
    "\n",
    "            for real_name in faults_to_include:                            \n",
    "                if real_name in line:           \n",
    "                    #important for changing the fault name that is associated with the coordinates, initiated above as a global variable\n",
    "                    name = real_name\n",
    "                    #initiates and resets the coordinates variable in conjuntion with the name above\n",
    "                    coordinates = []\n",
    "                    print(name)\n",
    "                    #if we have the name of one of the faults (from the faults_to_include list) we want in the real_name line then we add a yes to the tracker\n",
    "                    included_fault_tracker.append('yes') \n",
    "                else:\n",
    "                    #going to be a lot of no\n",
    "                    included_fault_tracker.append('no')\n",
    "            #print(included_fault_tracker)\n",
    "            \n",
    "        elif line.startswith(\"#\"): \n",
    "            #this file has 15 '#'s at the beginning and I wanted to be explicit with what happens there\n",
    "            pass  \n",
    "        \n",
    "        else:     \n",
    "            #flag saying that we're in the coordinates portion of the fault\n",
    "            is_number = True \n",
    "            \n",
    "            while is_number == True:                        \n",
    "                if 'yes' in included_fault_tracker: \n",
    "                    #print('sure')\n",
    "                    #changes the raw coordinate data to a comma seperated, adjusted to study area, list of floats in a list. Goes line by line and appends each pair: format [[165833.0625, 173051.0], [165133.0, 172049.5],...\n",
    "                    adjust_to_wb()\n",
    "                else:                           \n",
    "                    pass\n",
    "                \n",
    "                break\n",
    "        #this is here to flag that we're not done with the coordinates of a particular fault yet, part of the wrapping process\n",
    "        Associated_with_current_fault = True  \n",
    "\n",
    "#instead of differentiating which fault is the last one, I just cut off the last comma\n",
    "with open(\"wb_wip.txt\", \"rb+\") as f:\n",
    "    f.seek(-3, os.SEEK_END)\n",
    "    f.truncate()\n",
    "#after we do all that we close the wb file\n",
    "with open(\"wb_wip.txt\", \"a\") as f:\n",
    "    f.write('\\n')\n",
    "    f.write('\\t')\n",
    "    f.write(']')\n",
    "    f.write('\\n')\n",
    "    f.write('}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obsoliete?\n",
    "def model_feature_string(model, name, dip_point, coordinates):\n",
    "    global feature_string\n",
    "    feature_string = '\"model\":\"' + str(model) + '\", \"name\":\"' + str(name) + '\", \"dip point\":\"' + str(dip_point) + '\", \"coordinates\":' + str(coordinates) + ',\\n'\n",
    "    return feature_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156687.5625   3877500.7500   -76.058300000\n"
     ]
    }
   ],
   "source": [
    "print(last_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_feature_string(model_name, feature_name, min_depth, max_depth, coordinates, is_subducting, dip_point):\n",
    "    \n",
    "    '''\n",
    "    Creates a string which is then written to a world builder file that initializes a world builder feature\n",
    "\n",
    "    model_name    = string specifying the WB model type you want for the feature \n",
    "    feature_name  = user specified string naming the feature (can be anything, for ease of reading the WB file)\n",
    "    min_depth     = minimum depth extent of the feature\n",
    "    max_depth     = maximum depth extenet of the feautre\n",
    "    coordinates   = array specifying the points which create a bounding volume of the feature\n",
    "    is_subducting = True or False, whether the feature is a subducting plate\n",
    "    dip_point     = if is_subducting=True, location of the dip point of the subducting slab    \n",
    "    '''\n",
    "    \n",
    "    if is_subducting == False:\n",
    "        feature_string = '\"model\":\"' + str(model_name) + '\", \"name\":\"' + str(feature_name) + '\", \"min depth\":' + str(min_depth) +', \"max depth\":' + \\\n",
    "                         str(max_depth) + ', \"coordinates\":' + str(coordinates) + ',\\n'\n",
    "    else:\n",
    "        feature_string = '\"model\":\"' + str(model_name) + '\", \"name\":\"' + str(feature_name) + '\", \"coordinates\":' + str(coordinates) + ', \"dip point\":' + str(dip_point) + ',\\n'\n",
    "    return feature_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_string(length, thickness, angle, top_truncation, coordinate, total_sections, segment_num, current_segment):\n",
    "\n",
    "    '''\n",
    "    Writes the string that defines segments of a slab to the world builder file\n",
    "\n",
    "    When initializing a slab in Worldbuilder, you must specify the same number of segments for each section along strike\n",
    "    of the slab, which is troublesome since some sections of slab are much longer than others. To get around this,\n",
    "    the slab is initialized with the same number of segments as the section with the maximum number of segments. \n",
    "    Then, sections with less than this number of segments are assigned filler sections with lengths of 0 m until\n",
    "    they reach the required number of segments\n",
    "\n",
    "    length          = the length of a given segment\n",
    "    thickness       = the thickness of a given segment\n",
    "    angle           = the dip of a given segment\n",
    "    coordinate      = the trench coordinate index coupled to the current section\n",
    "    total_sections  = the number of sections making up the slab\n",
    "    segment_num     = the number of segments making up each section\n",
    "    current_segment = the current segment index of a section\n",
    "    '''\n",
    " \n",
    "    string_total = ''\n",
    "    filler_segment_number = abs(len(thickness) - segment_num)\n",
    "    if current_segment < filler_segment_number:\n",
    "        if len(thickness[0]) > 1:\n",
    "            # Here we proceed as above, adding the segment strings until we reach the end of the array\n",
    "            string_total += '{\"length\":' + str(0.0) + ', \"thickness\":' + str([np.max(thickness), np.max(thickness)]) + ', \"angle\":' + str([0.0, 0.0]) + '},\\n'# \\\n",
    "                           # ', \"angle\":' + str([0,0]) + '},\\n'\n",
    "            return string_total\n",
    "        \n",
    "        else:\n",
    "            # Here we proceed as above, adding the segment strings until we reach the end of the array\n",
    "            string_total += '{\"length\":' + str(0.0) + ', \"thickness\":' + str([np.max(thickness)]) + ', \"angle\":' + str([0.0, 0.0]) + '},\\n'# \\\n",
    "                           # ', \"angle\":' + str([0,0]) + '},\\n'\n",
    "            return string_total\n",
    "        \n",
    "        # Now we have reached the end of the array, but need to fill out the amount of segments to reach the maximum\n",
    "        # segment number. Add segments with lengths of 1m, thicknesses of 1m, and dips of 1 degree until this is the case.\n",
    "    else:\n",
    "        if current_segment != segment_num - 1:\n",
    "            string_total = '{\"length\":' + str(length[current_segment - filler_segment_number]) + ', \"thickness\":' + str(thickness[current_segment - filler_segment_number]) + \\\n",
    "                            ', \"angle\":' + str(angle[current_segment - filler_segment_number]) + ', \"top truncation\":' + str(top_truncation) + '},\\n'\n",
    "            return string_total\n",
    "\n",
    "        elif current_segment == (segment_num - 1) and coordinate == total_sections:\n",
    "            string_total += '{\"length\":' + str(length[current_segment - filler_segment_number]) + ', \"thickness\":' + str(thickness[current_segment - filler_segment_number]) + \\\n",
    "                        ', \"angle\":' + str(angle[current_segment - filler_segment_number]) + ', \"top truncation\":' + str(top_truncation) + '}]}\\n'\n",
    "            return string_total\n",
    "\n",
    "        else:\n",
    "            string_total += '{\"length\":' + str(length[current_segment - filler_segment_number]) + ', \"thickness\":' + str(thickness[current_segment - filler_segment_number]) + \\\n",
    "                        ', \"angle\":' + str(angle[current_segment - filler_segment_number]) + ', \"top truncation\":' + str(top_truncation) + '}]},\\n'\n",
    "            return string_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_section(world_builder_file, profile_directory, xshift, yshift, slab_thickness, top_truncation, coordinate_system):\n",
    "    \n",
    "    '''\n",
    "    Calculates dip, thickness, and length of segments then uses segment_string() to create the string for the world builder file.\n",
    "    This function has the option to vary the slab thickness between certain depths. If the varialbe slab_thickness is a scalar,\n",
    "    a constant thickness is assumed for the entire section. To vary thickness, slab_thickness must be an array where each entry is an \n",
    "    array with length two. The entries of this array are the thickness of the slab and the depth to where \n",
    "    that thickness occurs. For example, to have the slab be 100km thick between 0 <= depth <= 200km, and then\n",
    "    have the thickness increase to 150km for depth > 200km, the variable slab_thickness would need to be set as:\n",
    "\n",
    "    slab_thickness = [ [100e3, 200e3], [150e3, 1e10] ]\n",
    "\n",
    "    Where 1e10 was chosen to be a depth so high it would never be reached. Slab thickness and dip are varied gradually \n",
    "    down dip\n",
    "\n",
    "    world_builder_file = the name of the world builder file\n",
    "    profile_directory  = directory containing the world builder file\n",
    "    xshift             = the amount of shift in the x direction, m\n",
    "    yshift             = the amount of shift in the y direction, m\n",
    "    slab_thickness     = the thickness of the slab, scaler for uniform thickness, array for variable, km\n",
    "    '''\n",
    "  \n",
    "    # Import packages for spherical coordinate systems\n",
    "    import geopy\n",
    "    from geopy.distance import geodesic\n",
    "    from geopy.distance import distance\n",
    "    import pyproj\n",
    "    geodesic = pyproj.Geod(ellps='WGS84')\n",
    "    \n",
    "    # Create an array which stores the length of each profile, the longest profile determines the number of\n",
    "    # segments required for initializing the slab\n",
    "    length = []\n",
    "    for file in np.sort(os.listdir(profile_directory)):\n",
    "        length.append(len(np.loadtxt(fname=profile_directory + file)))\n",
    "    segment_num = max(length)\n",
    "    total_sections = len(os.listdir(profile_directory)) - 1\n",
    "    \n",
    "    # This loop initializes the slab with the correct number of segments\n",
    "    world_builder_file.write('\"segments\":[\\n')\n",
    "    for i in range(segment_num):\n",
    "        if i != segment_num - 1:\n",
    "            world_builder_file.write('{\"length\":0, \"thickness\":[0.0], \"angle\":[0]},\\n')\n",
    "        else:\n",
    "            world_builder_file.write('{\"length\":0, \"thickness\":[0.0], \"angle\":[0]}],\\n\\n')\n",
    "\n",
    "    # This loops through all sections and determines the thickness, dip, and length of each segment\n",
    "    world_builder_file.write('    \"sections\":[')\n",
    "    index = 0\n",
    "    for file in np.sort(os.listdir(profile_directory)):\n",
    "        index += 1\n",
    "        filename = os.path.join(profile_directory, file)\n",
    "\n",
    "        track_x = np.loadtxt(fname=filename, usecols=0) + xshift\n",
    "        track_y = np.loadtxt(fname=filename, usecols=1) + yshift\n",
    "        track_z = np.loadtxt(fname=filename, usecols=2)\n",
    "\n",
    "        slab_length = 0\n",
    "        segment_length = []\n",
    "        dip_holder = [0]\n",
    "        \n",
    "        # Here we check to see if the thickness is set to vary along the slab by checking if slab_thickness is\n",
    "        # a scalar or not. Dip is also computed and stored for output to the world builder file here\n",
    "        if hasattr(slab_thickness, \"__len__\"):\n",
    "            thick_holder = [slab_thickness[index - 1][:, 0][0]]\n",
    "            for i in range(1, len(track_z)):\n",
    "                thick_index = np.min(np.where( slab_thickness[index - 1][:, 1] > np.abs(track_z[i]) ))\n",
    "                thick_holder.append(slab_thickness[index - 1][:, 0][thick_index])\n",
    "                \n",
    "                if coordinate_system == 'Cartesian':\n",
    "                    slab_cart_proj = np.sqrt( (track_x[i] - track_x[i - 1])**2 + (track_y[i] - track_y[i - 1])**2 )\n",
    "                    slab_length = np.sqrt( (track_x[i] - track_x[i - 1])**2 + (track_y[i] - track_y[i - 1])**2 + (track_z[i] - track_z[i - 1])**2)\n",
    "                    riserun = (track_z[i - 1] - track_z[i]) / (slab_cart_proj)\n",
    "                    \n",
    "                elif coordinate_system == 'Spherical':\n",
    "                    fwd_az, back_az, slab_cart_proj_m = geodesic.inv(track_x[i-1], track_y[i-1], track_x[i], track_y[i])\n",
    "                    slab_cart_proj = slab_cart_proj_m / 1e3\n",
    "                    slab_length = np.sqrt( slab_cart_proj**2 + (track_z[i] - track_z[i - 1])**2)\n",
    "                    riserun = (track_z[i - 1] - track_z[i]) / (slab_cart_proj)\n",
    "                    \n",
    "                segment_length.append(slab_length * 1000)\n",
    "                dip_holder.append(np.rad2deg(np.arctan(abs(riserun))))\n",
    "                \n",
    "            segment_thickness = []\n",
    "            for k in range(len(thick_holder) - 1):\n",
    "                if k != int(len(thick_holder) - 1):\n",
    "                    segment_thickness.append([thick_holder[k], thick_holder[k + 1]])\n",
    "                else:\n",
    "                    segment_thickness.append([thick_holder[k]])\n",
    "         \n",
    "        else:\n",
    "            segment_thickness = []\n",
    "            for i in range(1, len(track_z)):\n",
    "                segment_thickness.append([slab_thickness])\n",
    "                \n",
    "                if coordinate_system == 'Cartesian':\n",
    "                    slab_cart_proj = np.sqrt( (track_x[i] - track_x[i - 1])**2 + (track_y[i] - track_y[i - 1])**2 )\n",
    "                    slab_length = np.sqrt( (track_x[i] - track_x[i - 1])**2 + (track_y[i] - track_y[i - 1])**2 + (track_z[i] - track_z[i - 1])**2)\n",
    "                    \n",
    "                elif coordinate_system == 'Spherical':\n",
    "                    fwd_az, back_az, slab_cart_proj_m = geodesic.inv(track_x[i-1], track_y[i-1], track_x[i], track_y[i])\n",
    "                    slab_cart_proj = slab_cart_proj_m / 1e3\n",
    "                    slab_length = np.sqrt( slab_cart_proj**2 + (track_z[i] - track_z[i - 1])**2)\n",
    "                    \n",
    "                riserun = (track_z[i - 1] - track_z[i]) / (slab_cart_proj)\n",
    "                segment_length.append(slab_length * 1000)\n",
    "                dip_holder.append(np.rad2deg(np.arctan(abs(riserun))))\n",
    "                \n",
    "        dips = []\n",
    "        for k in range(len(dip_holder) - 1):\n",
    "            if k != int(len(dip_holder) - 1):\n",
    "                dips.append([dip_holder[k], dip_holder[k + 1]])\n",
    "            else:\n",
    "                dips.append([dip_holder[k]])\n",
    "        \n",
    "        # Write to the World Builder File\n",
    "        world_builder_file.write('    {\"coordinate\":' + str(index - 1) + ',\\n')\n",
    "        world_builder_file.write('     \"segments\":[')\n",
    "        for current_segment in range(segment_num):\n",
    "            world_builder_file.write('    ' + segment_string(segment_length, segment_thickness, dips, top_truncation, index - 1, total_sections, segment_num, current_segment))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
